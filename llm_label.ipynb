{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# import ollama\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import re\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of DF:  246\n",
      "category            146\n",
      "post_date           146\n",
      "post_title          146\n",
      "comment_date        146\n",
      "comment_votes       146\n",
      "comment_body         69\n",
      "comment_stance      181\n",
      "comment_argument    169\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('./data/manually_labelled.csv')\n",
    "# print(df.head(2))\n",
    "\n",
    "print('Length of DF: ', len(df))\n",
    "print(df.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "category            100\n",
      "post_date           100\n",
      "post_title          100\n",
      "comment_date        100\n",
      "comment_votes       100\n",
      "comment_body        177\n",
      "comment_stance       65\n",
      "comment_argument     77\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.notna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    if isinstance(text, str):\n",
    "        text = re.sub(r'\\[.*?\\]\\(.*?\\)', '', text)  \n",
    "        text = re.sub(r'[^a-zA-Z0-9\\s.,!?]', '', text)  \n",
    "        text = re.sub(r'\\s+', ' ', text)\n",
    "        return text.strip()\n",
    "    return ''\n",
    "\n",
    "def filter_bot(text):\n",
    "    return isinstance(text, str) and 'i am a bot' in text.lower() #iamabot' in re.sub(r'\\s+', '', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am a bot, and this action was performed automatically. Please if you have any questions or concerns.\n",
      "I am a bot, and this action was performed automatically. Please if you have any questions or concerns.\n",
      "I am a bot. Any complaints suggestions to rContextualBot thanks\n",
      "I am a bot, and this action was performed automatically. Please if you have any questions or concerns.\n",
      "I am a bot, and this action was performed automatically. Please if you have any questions or concerns.\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for idx, text in df['comment_body'].items():\n",
    "    cleaned_text = clean_text(text)\n",
    "    if filter_bot(cleaned_text):\n",
    "        count += 1\n",
    "        print(cleaned_text)\n",
    "        df.drop(idx, inplace=True)\n",
    "\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[df['comment_body'].isna() & df['comment_stance'].isna()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      Snapshot of _Minister failing to act to reduce...\n",
       "2      An archived version can be found [here](https:...\n",
       "8      The amount of money wasted on completely bollo...\n",
       "10     I once worked on a project that installed a ha...\n",
       "15     So in other words smaller employers don’t need...\n",
       "                             ...                        \n",
       "234    We all know that ultimately the facts are that...\n",
       "238    They just leave it.  You've got senior doctors...\n",
       "240    People earning 50k will not bother applying fo...\n",
       "242                       Is it incompetence?  Laziness?\n",
       "245    Today's academia has so many failings - it act...\n",
       "Name: comment_body, Length: 107, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['comment_stance'].isna() & df['comment_body'].notna()]['comment_body']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[~df['comment_stance'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6      disapprove\n",
       "11     disapprove\n",
       "12     disapprove\n",
       "13     disapprove\n",
       "17     disapprove\n",
       "          ...    \n",
       "223       approve\n",
       "232       approve\n",
       "235    disapprove\n",
       "236       approve\n",
       "243       approve\n",
       "Name: comment_stance, Length: 65, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['comment_stance']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['comment_body'] = df['comment_body'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['new_stance'] = df['comment_stance'].replace({'approve': 'agree', 'disapprove': 'disagree'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comment_stance\n",
      "disapprove    43\n",
      "approve       22\n",
      "Name: count, dtype: int64\n",
      "new_stance\n",
      "disagree    43\n",
      "agree       22\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df['comment_stance'].value_counts())\n",
    "print(df['new_stance'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_content(text):\n",
    "    text = re.sub(r'[^A-Za-z0-9\\s]', '', text.lower())\n",
    "\n",
    "    try:\n",
    "        stance_index = text.index('stance')\n",
    "    except ValueError:\n",
    "        stance_index = 0\n",
    "\n",
    "    try:\n",
    "        arg_index = text.index('rationale')\n",
    "    except ValueError:\n",
    "        arg_index = 0\n",
    "\n",
    "\n",
    "    if arg_index>stance_index:\n",
    "        stance_text = text[stance_index:arg_index]\n",
    "    else:\n",
    "        stance_text = text[stance_index:]\n",
    "\n",
    "    stance = 'disapprove' if 'disagree' in stance_text else 'approve'\n",
    "    # stance = 'disagree' if 'disagree' in stance_text else 'agree'\n",
    "    # stance = 'disagree' if 'no' in stance_text else 'agree'\n",
    "\n",
    "    argument = text[arg_index:].split(' ')\n",
    "    \n",
    "    try:\n",
    "        argument.remove('rationale')\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    argument = ' '.join(argument)\n",
    "\n",
    "    # stat_index = text.index('strategy')\n",
    "    \n",
    "    # stat = text[stat_index:].split(' ')\n",
    "    # stat.remove('strategy')\n",
    "    # stat = ' '.join(stat)\n",
    "\n",
    "    return stance, argument#, stat\n",
    "\n",
    "def strip_recheck(text):\n",
    "    text = re.sub(r'[^A-Za-z0-9\\s]', '', text.lower())\n",
    "    if 'yes' in text:\n",
    "        return True \n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM prompt template\n",
    "def response_prompt(title, comment):\n",
    "    return f\"\"\"You are an expert in political discourse analysis.\n",
    "\n",
    "    Post Title: \"{title}\"\n",
    "    Comment: \"{comment}\"\n",
    "\n",
    "    Task 1: Does the comment AGREE or DISAGREE with the opinion expressed in the title? Reply only with 'agree', 'disagree'.\n",
    "\n",
    "    Task 2: Briefly explain the rationale behind the comment in 1-2 sentences.\n",
    "\n",
    "    Respond in the following format:\n",
    "    Stance: <stance>\n",
    "    Rationale: <explanation>\n",
    "    \"\"\"\n",
    "\n",
    "def recheck_prompt(title, comment, response):\n",
    "    res_dict = {\n",
    "        'approve': 'agree',\n",
    "        'disapprove': 'disagree'\n",
    "    }\n",
    "    response = res_dict[response]\n",
    "    return f\"\"\"\n",
    "    Post Title: \"{title}\n",
    "    Comment: \"{comment}\"\n",
    "    AI Response: \"{response}\"\n",
    "\n",
    "    The AI response says the comment {response} with the post title, is this correct?\n",
    "\n",
    "    Respond with only yes or no\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "\n",
    "def query_ollama(prompt, mdl_idx):\n",
    "    models_dict = { 0: 'gemma3:12b', 1: 'gemma3:4b', 2: 'deepseek-r1:8b'}\n",
    "    url = \"http://localhost:11434/api/generate\"\n",
    "    data = {\n",
    "        \"model\": models_dict[mdl_idx],\n",
    "        \"prompt\": prompt,\n",
    "        \"stream\": False\n",
    "    }\n",
    "    try:\n",
    "        response = requests.post(url, json=data)\n",
    "        response.raise_for_status()\n",
    "        return response.json()[\"response\"]\n",
    "    except Exception as e:\n",
    "        print(\"Error:\", e)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_on_df(df):\n",
    "    selected_mdl_idx = 0\n",
    "    for idx, row in tqdm(df.iterrows(), desc='Processing: ', total=len(df), dynamic_ncols=True):\n",
    "        prompt = response_prompt(row['post_title'], row['comment_body'])\n",
    "        llm_response = query_ollama(prompt, selected_mdl_idx) \n",
    "\n",
    "        if llm_response:\n",
    "            stance, argument = strip_content(llm_response)\n",
    "            check_prompt = recheck_prompt(row['post_title'], row['comment_body'], stance)\n",
    "            llm_check_response = query_ollama(check_prompt, selected_mdl_idx)\n",
    "            llm_check_flag = strip_recheck(llm_check_response)\n",
    "\n",
    "            # print('LLM Response: \\n', llm_response)\n",
    "            # print('LLM Check Response: \\n', llm_check_response)\n",
    "            # print('Check Flag: ', llm_check_flag)\n",
    "\n",
    "            if not llm_check_flag:\n",
    "                stance2 = 'disapprove' if stance=='approve' else 'approve'\n",
    "\n",
    "            df.at[idx, 'llm_stance'] = stance.lower() \n",
    "            df.at[idx, 'llm_stance2'] = stance2.lower()\n",
    "            df.at[idx, 'llm_argument'] = argument.lower() \n",
    "   \n",
    "        time.sleep(1)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|██████████| 65/65 [10:30<00:00,  9.69s/it]\n"
     ]
    }
   ],
   "source": [
    "result_df = apply_on_df(df)\n",
    "result_df.to_csv('data/llm_labelled_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score (Gemma3:12b)-recheck-v1: 0.8153846153846154\n",
      "classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     approve       0.66      0.95      0.78        22\n",
      "  disapprove       0.97      0.74      0.84        43\n",
      "\n",
      "    accuracy                           0.82        65\n",
      "   macro avg       0.81      0.85      0.81        65\n",
      "weighted avg       0.86      0.82      0.82        65\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ytrue, ypred = result_df['comment_stance'], result_df['llm_stance'].map(str.lower)\n",
    "acc_score = accuracy_score(ytrue, ypred)\n",
    "clf_report = classification_report(ytrue, ypred)\n",
    "cm = confusion_matrix(ytrue, ypred)\n",
    "\n",
    "print('Accuracy Score (Gemma3:12b)-recheck-v1:', acc_score)\n",
    "print('classification Report:')\n",
    "print(clf_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score (Gemma3:12b)-recheck-v1: 0.3230769230769231\n",
      "classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     approve       0.28      0.64      0.39        22\n",
      "  disapprove       0.47      0.16      0.24        43\n",
      "\n",
      "    accuracy                           0.32        65\n",
      "   macro avg       0.37      0.40      0.32        65\n",
      "weighted avg       0.40      0.32      0.29        65\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ytrue, ypred = result_df['comment_stance'], result_df['llm_stance2'].map(str.lower)\n",
    "acc_score = accuracy_score(ytrue, ypred)\n",
    "clf_report = classification_report(ytrue, ypred)\n",
    "cm = confusion_matrix(ytrue, ypred)\n",
    "\n",
    "print('Accuracy Score (Gemma3:12b)-recheck-v1:', acc_score)\n",
    "print('classification Report:')\n",
    "print(clf_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(cm, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score (DeepSeek-R1:8b): 0.7076923076923077\n",
      "classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     approve       0.56      0.68      0.61        22\n",
      "  disapprove       0.82      0.72      0.77        43\n",
      "\n",
      "    accuracy                           0.71        65\n",
      "   macro avg       0.69      0.70      0.69        65\n",
      "weighted avg       0.73      0.71      0.71        65\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ytrue, ypred = result_df['comment_stance'], result_df['llm_stance'].map(str.lower)\n",
    "acc_score = accuracy_score(ytrue, ypred)\n",
    "clf_report = classification_report(ytrue, ypred)\n",
    "cm = confusion_matrix(ytrue, ypred)\n",
    "\n",
    "print('Accuracy Score (DeepSeek-R1:8b):', acc_score)\n",
    "print('classification Report:')\n",
    "print(clf_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score (Gemma3:12b): 0.8153846153846154\n",
      "classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     approve       0.67      0.91      0.77        22\n",
      "  disapprove       0.94      0.77      0.85        43\n",
      "\n",
      "    accuracy                           0.82        65\n",
      "   macro avg       0.80      0.84      0.81        65\n",
      "weighted avg       0.85      0.82      0.82        65\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result_df = pd.read_csv('./data/llm_labelled.csv')\n",
    "ytrue, ypred = result_df['comment_stance'], result_df['llm_stance'].map(str.lower)\n",
    "acc_score = accuracy_score(ytrue, ypred)\n",
    "clf_report = classification_report(ytrue, ypred)\n",
    "cm = confusion_matrix(ytrue, ypred)\n",
    "\n",
    "print('Accuracy Score (Gemma3:12b):', acc_score)\n",
    "print('classification Report:')\n",
    "print(clf_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score (Gemma3:12b) - prompt - v1: 0.7692307692307693\n",
      "classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     approve       0.61      0.91      0.73        22\n",
      "  disapprove       0.94      0.70      0.80        43\n",
      "\n",
      "    accuracy                           0.77        65\n",
      "   macro avg       0.77      0.80      0.76        65\n",
      "weighted avg       0.83      0.77      0.78        65\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ytrue, ypred = result_df['comment_stance'], result_df['llm_stance'].map(str.lower)\n",
    "acc_score = accuracy_score(ytrue, ypred)\n",
    "clf_report = classification_report(ytrue, ypred)\n",
    "cm = confusion_matrix(ytrue, ypred)\n",
    "\n",
    "print('Accuracy Score (Gemma3:12b) - prompt - v1:', acc_score)\n",
    "print('classification Report:')\n",
    "print(clf_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "llm_stance\n",
       "disagree    33\n",
       "agree       32\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# result_df['llm_stance'] = result_df['llm_stance'].map({'disapprove':'disagree'})\n",
    "# result_df['llm_stance'].value_counts()\n",
    "result_df = pd.read_csv('./data/llm_labelled.csv')\n",
    "result_df['llm_stance'] = result_df['llm_stance'].replace({'disapprove': 'disagree', 'approve': 'approve'})\n",
    "result_df['llm_stance'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score (Gemma3:12b) - prompt - v0 - new_stance: 0.8153846153846154\n",
      "classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       agree       0.66      0.95      0.78        22\n",
      "    disagree       0.97      0.74      0.84        43\n",
      "\n",
      "    accuracy                           0.82        65\n",
      "   macro avg       0.81      0.85      0.81        65\n",
      "weighted avg       0.86      0.82      0.82        65\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ytrue, ypred = result_df['new_stance'], result_df['llm_stance'].map(str.lower)\n",
    "acc_score = accuracy_score(ytrue, ypred)\n",
    "clf_report = classification_report(ytrue, ypred)\n",
    "cm = confusion_matrix(ytrue, ypred)\n",
    "\n",
    "print('Accuracy Score (Gemma3:12b) - prompt - v0 - new_stance:', acc_score)\n",
    "print('classification Report:')\n",
    "print(clf_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "llm_stance\n",
       "agree       35\n",
       "disagree    30\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df['llm_stance'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score (Gemma3:12b) - prompt - v2 - new_stance: 0.7384615384615385\n",
      "classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       agree       0.57      0.91      0.70        22\n",
      "    disagree       0.93      0.65      0.77        43\n",
      "\n",
      "    accuracy                           0.74        65\n",
      "   macro avg       0.75      0.78      0.73        65\n",
      "weighted avg       0.81      0.74      0.74        65\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ytrue, ypred = result_df['new_stance'], result_df['llm_stance'].map(str.lower)\n",
    "acc_score = accuracy_score(ytrue, ypred)\n",
    "clf_report = classification_report(ytrue, ypred)\n",
    "cm = confusion_matrix(ytrue, ypred)\n",
    "\n",
    "print('Accuracy Score (Gemma3:12b) - prompt - v2 - new_stance:', acc_score)\n",
    "print('classification Report:')\n",
    "print(clf_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import requests\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "\n",
    "\n",
    "def clean_text(text):\n",
    "    if isinstance(text, str):\n",
    "        text = re.sub(r'\\[.*?\\]\\(.*?\\)', '', text)  \n",
    "        text = re.sub(r'[^a-zA-Z0-9\\s.,!?]', '', text)  \n",
    "        text = re.sub(r'\\s+', ' ', text)\n",
    "        return text.strip()\n",
    "    return ''\n",
    "\n",
    "def filter_bot(text):\n",
    "    return isinstance(text, str) and 'i am a bot' in text.lower() #iamabot' in re.sub(r'\\s+', '', text)\n",
    "\n",
    "def strip_content(text):\n",
    "    text = re.sub(r'[^A-Za-z0-9\\s]', '', text.lower())\n",
    "\n",
    "    try:\n",
    "        stance_index = text.index('stance')\n",
    "    except ValueError:\n",
    "        stance_index = 0\n",
    "\n",
    "    try:\n",
    "        arg_index = text.index('rationale')\n",
    "    except ValueError:\n",
    "        arg_index = len(text)\n",
    "\n",
    "    if arg_index > stance_index:\n",
    "        stance_text = text[stance_index:arg_index]\n",
    "    else:\n",
    "        stance_text = text[stance_index:]\n",
    "\n",
    "    stance = 'disapprove' if 'disagree' in stance_text else 'approve'\n",
    "\n",
    "    argument = text[arg_index:].split(' ')\n",
    "    try:\n",
    "        argument.remove('rationale')\n",
    "    except:\n",
    "        pass\n",
    "    argument = ' '.join(argument)\n",
    "\n",
    "    return stance, argument\n",
    "\n",
    "# Prompt templates\n",
    "def response_prompt(title, comment):\n",
    "    return f\"\"\"You are an expert in political discourse analysis.\n",
    "\n",
    "    Post Title: \"{title}\"\n",
    "    Comment: \"{comment}\"\n",
    "\n",
    "    Task 1: Does the comment AGREE or DISAGREE with the opinion expressed in the title? Reply only with 'agree', 'disagree'.\n",
    "\n",
    "    Task 2: Briefly explain the rationale behind the comment in 1-2 sentences.\n",
    "\n",
    "    Respond in the following format:\n",
    "    Stance: <stance>\n",
    "    Rationale: <explanation>\n",
    "    \"\"\"\n",
    "\n",
    "def query_ollama(prompt, mdl_idx):\n",
    "    models_dict = {0: 'gemma3:12b', 1: 'gemma3:4b', 2: 'deepseek-r1:8b'}\n",
    "    url = \"http://localhost:11434/api/generate\"\n",
    "    data = {\n",
    "        \"model\": models_dict[mdl_idx],\n",
    "        \"prompt\": prompt,\n",
    "        \"stream\": False\n",
    "    }\n",
    "    try:\n",
    "        response = requests.post(url, json=data)\n",
    "        response.raise_for_status()\n",
    "        return response.json()[\"response\"]\n",
    "    except Exception as e:\n",
    "        print(\"Error:\", e)\n",
    "        return \"\"\n",
    "\n",
    "def apply_on_df(df):\n",
    "    selected_mdl_idx = 0\n",
    "    for idx, row in tqdm(df.iterrows(), desc='Processing', total=len(df), dynamic_ncols=True):\n",
    "        # First pass\n",
    "        prompt1 = response_prompt(row['post_title'], row['comment_body'])\n",
    "        response1 = query_ollama(prompt1, selected_mdl_idx)\n",
    "        stance1, arg1 = strip_content(response1)\n",
    "\n",
    "        # Second independent recheck (no yes/no)\n",
    "        prompt2 = response_prompt(row['post_title'], row['comment_body'])\n",
    "        response2 = query_ollama(prompt2, selected_mdl_idx)\n",
    "        stance2, arg2 = strip_content(response2)\n",
    "\n",
    "        df.at[idx, 'llm_stance'] = stance1\n",
    "        df.at[idx, 'llm_argument'] = arg1\n",
    "        df.at[idx, 'llm_stance2'] = stance2\n",
    "        df.at[idx, 'llm_argument2'] = arg2\n",
    "\n",
    "        df.at[idx, 'llm_stance3'] = stance1 if stance1==stance2 else stance2\n",
    "\n",
    "        time.sleep(1)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def load_process_df():\n",
    "    df = pd.read_csv('./data/manually_labelled.csv')\n",
    "\n",
    "    for idx, text in df['comment_body'].items():\n",
    "        cleaned_text = clean_text(text)\n",
    "        if filter_bot(cleaned_text):\n",
    "            df.drop(idx, inplace=True)\n",
    "\n",
    "    df = df[~df['comment_stance'].isna()]\n",
    "    df['comment_body'] = df['comment_body'].apply(clean_text)\n",
    "\n",
    "    return df \n",
    "\n",
    "def save_log(acc_scores):\n",
    "    file_path = './data/log.txt'\n",
    "    with open(file_path, 'w') as f:\n",
    "        f.write(\n",
    "            f\"\\nAccuracy : {\":.2f\".format(acc_scores[0])}\\nAccuracy : {\":.2f\".format(acc_scores[1])}\\nAccuracy : {\":.2f\".format(acc_scores[2])}\"\n",
    "        )\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "df = load_process_df()\n",
    "result_df = apply_on_df(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8153846153846154, 0.8153846153846154, 0.8153846153846154]\n"
     ]
    }
   ],
   "source": [
    "# \n",
    "y_true, ypred1, ypred2, ypred3 = result_df['comment_stance'], result_df['llm_stance'], result_df['llm_stance2'], result_df['llm_stance3']\n",
    "acc_score1 = accuracy_score(y_true, ypred1)\n",
    "acc_score2 = accuracy_score(y_true, ypred2)\n",
    "acc_score3 = accuracy_score(y_true, ypred3)\n",
    "save_log([acc_score1, acc_score2, acc_score3])\n",
    "\n",
    "print([acc_score1, acc_score2, acc_score3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.to_csv('./data/llm_labelled_2405.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_process_df():\n",
    "    df = pd.read_csv('./data/manually_labelled.csv')\n",
    "\n",
    "    for idx, text in df['comment_body'].items():\n",
    "        cleaned_text = clean_text(text)\n",
    "        if filter_bot(cleaned_text):\n",
    "            df.drop(idx, inplace=True)\n",
    "\n",
    "    df = df[~df['comment_stance'].isna()]\n",
    "    df['comment_body'] = df['comment_body'].apply(clean_text)\n",
    "\n",
    "    return df \n",
    "\n",
    "cleaned_df = load_process_df()\n",
    "cleaned_df.to_csv('./data/cleaned_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
